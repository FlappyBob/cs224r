# Behavior Cloning 实验结果分析

## 📊 实验结果汇总

### 1. Ant 环境（BC 成功达到 30%）

| 指标 | 数值 |
|------|------|
| **BC 平均回报** | 4644.26 ± 98.19 |
| **专家平均回报** | 4713.65 ± 12.20 |
| **性能比** | **98.5%** ✅ |
| **是否达到 30%** | ✅ 是（远超要求） |

**分析**：
- BC 在 Ant 环境表现**非常好**，几乎达到专家水平
- Ant 环境相对简单，专家数据覆盖了大部分状态空间
- BC 能够很好地学习专家的行为模式

---

### 2. Hopper 环境（BC 无法达到 30%）

| 指标 | 数值 |
|------|------|
| **BC 平均回报** | 801.55 ± 236.34 |
| **专家平均回报** | 3772.67 ± 1.95 |
| **性能比** | **21.2%** ❌ |
| **是否达到 30%** | ❌ 否（低于要求） |

**关键观察**：
- BC 性能仅为专家的 **21.2%**，远低于 30% 阈值
- **标准差很大**（236.34），说明性能不稳定
- **平均轨迹长度**：250.76 步（专家是 1000 步），说明策略经常提前失败

---

## 🔍 为什么 Hopper 表现差？

### 1. **分布偏移（Distribution Shift）问题**

这是 Behavior Cloning 的**核心问题**：

```
训练时：BC 看到的观测来自专家轨迹（专家很少犯错）
测试时：BC 自己运行，会进入专家从未访问过的状态
结果：BC 在这些新状态下不知道该怎么办
```

**Hopper 的特点**：
- 需要精确的平衡控制
- 一旦偏离专家轨迹，容易摔倒
- 摔倒后进入新状态，BC 没有见过，无法恢复

### 2. **误差累积（Compounding Errors）**

```
步骤 1: BC 动作有微小偏差
    ↓
步骤 2: 偏差导致状态偏移
    ↓
步骤 3: 状态偏移导致更大的动作偏差
    ↓
...（恶性循环）
    ↓
最终：完全偏离，摔倒
```

### 3. **数据覆盖不足**

- 专家数据只包含**成功的轨迹**
- 没有包含**从错误中恢复**的示例
- BC 无法学习如何处理错误情况

---

## 📈 对比分析

| 环境 | BC 性能 | 专家性能 | 性能比 | 难度 |
|------|---------|----------|--------|------|
| **Ant** | 4644.26 | 4713.65 | 98.5% | 低 |
| **Hopper** | 801.55 | 3772.67 | 21.2% | 高 |

**为什么 Ant 表现好，Hopper 表现差？**

1. **状态空间复杂度**：
   - Ant：6 条腿，容错性高，即使有小偏差也能恢复
   - Hopper：单腿，需要精确平衡

2. **任务稳定性**：
   - Ant：主要是向前移动，相对简单
   - Hopper：需要连续跳跃和平衡，更脆弱

3. **错误恢复**：
   - Ant：多腿支撑，容易从错误中恢复
   - Hopper：一旦失去平衡，很难恢复

---

## 💡 改进方向

### 1. **DAgger（Dataset Aggregation）**
- 让 BC 在环境中运行
- 收集 BC 访问的状态
- 用专家重新标注这些状态
- 这样 BC 就能学习"在错误状态下该怎么做"

### 2. **增加训练数据**
- 收集更多专家轨迹
- 包含更多样化的场景

### 3. **数据增强**
- 在专家数据中添加噪声
- 模拟分布偏移的情况

### 4. **更复杂的网络**
- 增加网络容量
- 使用更好的正则化

---

## ✅ 作业要求检查

### Problem 1: Behavior Cloning

✅ **任务 1**：Ant 环境达到 30% 专家性能
- BC: 4644.26，专家: 4713.65
- 性能比: 98.5% ✅

✅ **任务 2**：一个环境无法达到 30% 专家性能
- Hopper: BC 801.55，专家 3772.67
- 性能比: 21.2% ❌

### 结果表格

| 环境 | BC 平均回报 | BC 标准差 | 专家平均回报 | 性能比 | 达到 30%？ |
|------|------------|-----------|-------------|--------|-----------|
| Ant-v4 | 4644.26 | 98.19 | 4713.65 | 98.5% | ✅ 是 |
| Hopper-v4 | 801.55 | 236.34 | 3772.67 | 21.2% | ❌ 否 |

**注意**：两个实验使用相同的网络结构（2层，64隐藏单元）、相同的数据量、相同的训练迭代次数，确保公平比较。

---

## 🎯 下一步：超参数实验

接下来需要选择一个超参数进行实验，例如：
- 训练步数（`num_agent_train_steps_per_iter`）
- 学习率（`learning_rate`）
- 网络大小（`size` 或 `n_layers`）
- 训练数据量

建议选择**训练步数**，因为它直接影响模型的学习程度。

